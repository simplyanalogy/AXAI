{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing AIR and comparing with chi2 and mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *\n",
    "from random import randint\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "#FOR CHI-SQUARE - MUTUAL INFORMATION\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "#FOR PLOT\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# evaluation of a model using all input features\n",
    "from pandas import read_csv\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS TO BE TESTED\n",
    "def xor(x,y): #utility\n",
    "    return (not(x) and y) or (x and not(y))  \n",
    "        \n",
    "def g1(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if (x1 and (x2 or x3)):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def g2(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if (not(x1) and x2) or (x1 and not(x2)) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def g3(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if xor(xor(x1,x2),x3):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def g4(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if (x1+x2+x3+x4+x5+x6+x7+x8+x9+x10==3):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def g5(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if (x1 or x2 or x3) and (x4 or not(x5) or x6):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def g6(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if (x1 and (x2 or not (x3))):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def g7(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    if (x1 + x2 + x3 == 2):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 1:  Dataset generation and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create initial artificial dataset of 1024 elements a = a binary CSV file for Boolean function'''\n",
    "'''The class of a is the last element in a raw. The class is given as a Boolean function f.'''\n",
    "dataset_csv= \"dataset.csv\"\n",
    "\n",
    "def create_csv_dataset(f):\n",
    "    result=open(dataset_csv, 'w')\n",
    "    with result as outfile:\n",
    "        for i1,i2,i3,i4,i5,i6,i7,i8,i9,i10 in itertools.product(range(2),range(2),range(2),range(2),range(2),range(2),range(2),range(2),range(2),range(2)):\n",
    "            cl = f(i1,i2,i3,i4,i5,i6,i7,i8,i9,i10)\n",
    "            outfile.write(str(i1)+\",\"+str(i2)+\",\"+str(i3)+\",\"+str(i4)+\",\"+str(i5)+\",\"+str(i6)+\",\"+\n",
    "                                            str(i7)+\",\"+str(i8)+\",\"+str(i9)+\",\"+str(i10)+\",\"+str(cl)+\"\\n\")\n",
    "    print(\"Dataset successfully created with the class function you have chosen.\")\n",
    "    \n",
    "#GENERATE RANDOM SAMPLE SET OF size ELEMENTS FROM A DATASET\n",
    "def generate_sample_set(dataset,size):\n",
    "    rdataset=shuffle(dataset)\n",
    "    sample_set= rdataset[:size]\n",
    "    #sample_set.astype(str) #FOR UCI DATA\n",
    "    return sample_set\n",
    "\n",
    "# LOADING METHODS\n",
    "def load_dataset_np(filename): #WHEN DATA ARE NUMBERS\n",
    "    data = np.loadtxt(filename, dtype=\"str\",delimiter=\",\")\n",
    "    data.astype(str)\n",
    "    X = data[:, :-1]\n",
    "    y = data[:,-1]\n",
    "    return data, X, y\n",
    "\n",
    "def load_dataset_panda(filename):  #WHEN DATA ARE STRINGS LIKE A, A, C, etc...\n",
    "    dataset = read_csv(filename, header=None)\n",
    "    data = dataset.values\n",
    "    data.astype(str)\n",
    "    X = data[:, :-1]\n",
    "    y = data[:,-1]\n",
    "    return data, X, y\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 2: Compute pairs from S, build  full profile for all pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPUTE ALL PAIRS FROM SAMPLE SET\n",
    "def all_pairs(sample_set):\n",
    "    n=sample_set.shape[0]\n",
    "    test_list=[]\n",
    "    for i in range(n):\n",
    "        test_list.append(sample_set[i])\n",
    "    set_of_pairs = list(combinations(test_list, 2)) \n",
    "    return set_of_pairs\n",
    "\n",
    "def mask_item(a,m):  # a = [1,0,...,cl(a)] \n",
    "    masked_a=[x and y for x,y in zip(a,m)]\n",
    "    return masked_a\n",
    "\n",
    "def build_profile(a,b,dim): #  A profile is a vector of dim 10 but len(a) = 11\n",
    "    profile=[]\n",
    "    for i in range(dim):\n",
    "        if a[i]==b[i]:\n",
    "            profile.append(-1)\n",
    "        else:\n",
    "            profile.append(int(a[i]))\n",
    "    return profile\n",
    "    \n",
    "# full profile =[a,b,profile(a,b),xor,masked(a),masked(b),masked_profile]\n",
    "def build_pair_with_full_profile(a,b,dim,mask): #a = [a, cl(a)] and b  2 vectors of same dim with class included\n",
    "    profile=build_profile(a,b,dim)\n",
    "    class_a=a[dim]\n",
    "    class_b=b[dim]\n",
    "    masked_a=mask_item(a,mask)\n",
    "    masked_b=mask_item(b,mask)\n",
    "    masked_profile=build_profile(masked_a,masked_b,dim)\n",
    "    return [a,b,profile,xor(class_a,class_b),masked_a,masked_b,masked_profile]\n",
    "        \n",
    "#profile(a,b) != profile(b,a)\n",
    "def create_all_pairs_and_profile(set_of_pairs,dim,mask): #[a,b,[-1 agreement, a_i where disag],xor(cl(a),cl(b))]\n",
    "    all_pairs_and_profiles=[]\n",
    "    for (a,b) in set_of_pairs:\n",
    "        full_profile=build_pair_with_full_profile(a,b,dim,mask)\n",
    "        all_pairs_and_profiles.append(full_profile)\n",
    "    return all_pairs_and_profiles\n",
    "\n",
    "#Filtering full profiles\n",
    "def opposite(bool):\n",
    "    return 1 - bool\n",
    "\n",
    "def are_matching_profiles(p1,p2): # take care of the fact that (a,b) should be equiv to (b,a) in term of profile\n",
    "    if p1==p2:\n",
    "        return True\n",
    "    else:\n",
    "        answer = True\n",
    "        for i in range(len(p1)):\n",
    "            b= (p1[i]==-1) and (p2[i]==-1)\n",
    "            answer = answer and (b or (p1[i]==opposite(p2[i])))\n",
    "        return answer\n",
    "            \n",
    "def get_all_pairs_from_profile(profile,all_pairs_and_profiles,masked=False):\n",
    "    matching_profiles=[]\n",
    "    index=2\n",
    "    if masked:\n",
    "        index=6\n",
    "    for p in all_pairs_and_profiles: #p=[a,b,profile(a,b),xor,masked(a),masked(b),masked_profile]\n",
    "        if are_matching_profiles(p[index],profile):\n",
    "            matching_profiles.append(p)\n",
    "    return matching_profiles\n",
    "\n",
    "def get_all_pairs_from_profile_with_class_info(cl,profile,all_pairs_and_profiles,masked):\n",
    "    matching_profiles = get_all_pairs_from_profile(profile,all_pairs_and_profiles,masked)\n",
    "    matching_profiles_same_class=[]\n",
    "    matching_profiles_class_change=[]\n",
    "    for p in matching_profiles:\n",
    "        if (p[0][10]==cl) and (p[3]==0): #cl(a) = p[0][10]\n",
    "            matching_profiles_same_class.append(p)\n",
    "        elif (p[0][10]==cl) and (p[3]!=0):\n",
    "            matching_profiles_class_change.append(p)\n",
    "    return matching_profiles_same_class, matching_profiles_class_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTION 3: Define utilities for chi2 and mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc\n",
    "    \n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n",
    "\n",
    "def prepare_all(X, y, test_size, random_state=1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
    "    X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "    y_train_enc, _ = prepare_targets(y_train, y_test)\n",
    "    return X_train_enc, y_train_enc, X_test_enc\n",
    " \n",
    "#TESTING WITH ALL FEATURES\n",
    "# feature selection chi2\n",
    "def select_all_features_chi2(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection mutual information\n",
    "def select_all_features_mutual(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "#TESTING WITH 4 BEST FEATURES\n",
    "# feature selection\n",
    "def select_k_features_chi2(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection mutual information\n",
    "def select_k_features_mutual(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 4: Define AIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dis is never empty because a is always distinct from b\n",
    "def Dis(a,b,list_of_attributes):  #disagreement set between Boolean vectors of same dimension\n",
    "    dis=[]\n",
    "    for i in list_of_attributes:\n",
    "        if a[i] != b[i]:\n",
    "            dis.append(i)\n",
    "    return dis\n",
    "\n",
    "def air(dim,attribute,list_of_attributes,set_of_pairs):\n",
    "    m_att=0\n",
    "    ag_att=0\n",
    "    for (a,b) in set_of_pairs:\n",
    "        if Dis(a[0:dim],b[0:dim],list_of_attributes)==[attribute]: \n",
    "            ag_att+=1\n",
    "            if a[dim]==b[dim]:\n",
    "                m_att+=1\n",
    "    ratio=-1\n",
    "    if ag_att!=0:\n",
    "        ratio=m_att/ag_att\n",
    "    return ratio\n",
    "        \n",
    "def select_features_air(dim,list_of_attributes,set_of_pairs):\n",
    "    scores=[]\n",
    "    for attribute in list_of_attributes:\n",
    "        ratio=air(dim,attribute,list_of_attributes,set_of_pairs)\n",
    "        scores.append(ratio)\n",
    "    return scores        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 5: Comparing AIR - chi-square - mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully created with the class function you have chosen.\n",
      "****INFORMATION ON INITIAL DATA *******\n",
      "dataset: dataset.csv size 1024 dimension: 10  - with 784 elements in class 1.\n",
      "air & 0.17 & 0.18 & 0.17 & 0.16 & 0.16 & 0.16 & 0.0 & 0.0 & 0.0 & 0.0\\\n",
      "chi2 & 0.17 & 0.14 & 0.17 & 0.18 & 0.18 & 0.16 & 0.0 & 0.0 & 0.0 & 0.0\\\n",
      "mi & 0.15 & 0.12 & 0.16 & 0.18 & 0.15 & 0.13 & 0.01 & 0.02 & 0.01 & 0.03\\\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "f=g5\n",
    "create_csv_dataset(f)\n",
    "#filename='datasets/breast-cancer-out.csv'\n",
    "#filename='datasets/HIV.csv'\n",
    "#filename='datasets/mushroom.csv'\n",
    "#filename='datasets/HIV-reduced-air.csv'\n",
    "filename=\"dataset.csv\"\n",
    "dataset, X, y = load_dataset_panda(filename)\n",
    "#INFO\n",
    "dataset_size=dataset.shape[0]\n",
    "dimension=dataset.shape[1] - 1\n",
    "positive= np.sum(dataset, axis = 0)[dimension]\n",
    "print(\"****INFORMATION ON INITIAL DATA *******\")\n",
    "print(\"dataset:\",filename,\"size\",dataset_size,\"dimension:\",dimension,\" - with\",positive,\"elements in class 1.\")\n",
    "\n",
    "#INIT\n",
    "#create list of attribute as index 0, 1, ...\n",
    "list_of_attributes=[]\n",
    "for i in range(dimension):\n",
    "    list_of_attributes.append(i)\n",
    "\n",
    "sample_ratio=0.33\n",
    "sample_size = int(dataset_size*sample_ratio)\n",
    "\n",
    "number_of_test=10\n",
    "mean_air_scores = [0]*dimension\n",
    "mean_chi_scores = [0]*dimension\n",
    "mean_mut_scores = [0]*dimension\n",
    "for u in range(number_of_test):\n",
    "    #MAIN TESTING LOOP\n",
    "    sample_set = generate_sample_set(dataset,sample_size)\n",
    "    list_of_pairs = all_pairs(sample_set)\n",
    "    air_scores = select_features_air(dimension,list_of_attributes,list_of_pairs)\n",
    "    air_scores=[1-k for k in air_scores]\n",
    "#NOT SURE WE TEST ON THE SAME SET BECAUSE OF TEST_SIZE PARAM IN PREPARE\n",
    "    X_train_enc, y_train_enc, X_test_enc=prepare_all(X, y, test_size=sample_ratio, random_state=1)\n",
    "    X_train_chi, X_test_chi, fs_chi = select_all_features_chi2(X_train_enc, y_train_enc, X_test_enc)\n",
    "    X_train_mut, X_test_mut, fs_mut = select_all_features_mutual(X_train_enc, y_train_enc, X_test_enc)\n",
    "#All scores are normalized\n",
    "#NORMALIZATION FACTORS\n",
    "    Z_air,Z_chi,Z_mi=0,0,0\n",
    "    for i in range(dimension):\n",
    "        Z_air+=air_scores[i]\n",
    "        Z_chi+=fs_chi.scores_[i]\n",
    "        Z_mi+=fs_mut.scores_[i]\n",
    "    #UPDATE MEAN SCORES BY ADDING NORMALIZED SCORES IN [0,1]  +0.01 to avoid division by 0\n",
    "    for j in range(dimension):\n",
    "        mean_air_scores[j]+= air_scores[j]/(Z_air + 0.01)\n",
    "        mean_chi_scores[j]+= fs_chi.scores_[j]/(Z_chi + 0.01)\n",
    "        mean_mut_scores[j]+= fs_mut.scores_[j]/(Z_mi + 0.01)\n",
    "\n",
    "mean_air_scores = [a*(1/number_of_test) for a in mean_air_scores]\n",
    "mean_chi_scores = [a*(1/number_of_test) for a in mean_chi_scores]\n",
    "mean_mut_scores = [a*(1/number_of_test) for a in mean_mut_scores]\n",
    "\n",
    "'''\n",
    "pyplot.title(\"AIR\")\n",
    "pyplot.bar([i for i in range(len(air_scores))], air_scores)\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.title(\"CHI-SQUARE\")\n",
    "pyplot.bar([i for i in range(len(fs_chi.scores_))], fs_chi.scores_*(1/Z_chi))\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.title(\"MUTUAL INFORMATION\")\n",
    "pyplot.bar([i for i in range(len(fs_mut.scores_))], fs_mut.scores_*(1/Z_mi))\n",
    "pyplot.show()\n",
    "'''  \n",
    "\n",
    "#PREPARE FOR LATEX\n",
    "#AIR\n",
    "latex_line=\"\"\n",
    "for i in range(dimension):\n",
    "    latex_line+=\" & \" +str(round(mean_air_scores[i],2))\n",
    "print(\"air\"+latex_line+\"\\\\\")\n",
    "\n",
    "#CHI_SQUARE\n",
    "latex_line=\"\"\n",
    "for i in range(len(fs_chi.scores_)):\n",
    "    latex_line+=\" & \" +str(round(mean_chi_scores[i],2))\n",
    "print(\"chi2\"+latex_line+\"\\\\\")\n",
    "\n",
    "#MUTUAL INF\n",
    "latex_line=\"\"\n",
    "for i in range(len(fs_mut.scores_)):\n",
    "    latex_line+=\" & \" +str(round(mean_mut_scores[i],2))\n",
    "print(\"mi\"+latex_line+\"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 6: Comparing the attribute relevance methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TEST ACCURACY WITH FULL DATASET\n",
    "def test_uci(X, y, all=True):\n",
    "    accuracy_full, accuracy_chi2, accuracy_mi=0,0,0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "    X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "    y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "    model = LogisticRegression(solver='lbfgs')\n",
    "    model.fit(X_train_enc, y_train_enc)\n",
    "    # evaluate the model\n",
    "    yhat = model.predict(X_test_enc)\n",
    "    # evaluate predictions\n",
    "    accuracy_full = accuracy_score(y_test_enc, yhat)\n",
    "    \n",
    "    if all:\n",
    "        # CHI2 k feature selection\n",
    "        X_train_fs, X_test_fs, fs = select_k_features_chi2(X_train_enc, y_train_enc, X_test_enc)\n",
    "        model = LogisticRegression(solver='lbfgs')\n",
    "        model.fit(X_train_fs, y_train_enc)\n",
    "        # evaluate the model\n",
    "        yhat = model.predict(X_test_fs)\n",
    "        # evaluate predictions\n",
    "        accuracy_chi2 = accuracy_score(y_test_enc, yhat)\n",
    "\n",
    "        # MUTUAL INFO k feature selection\n",
    "        X_train_fs, X_test_fs, fs = select_k_features_mutual(X_train_enc, y_train_enc, X_test_enc)\n",
    "        model = LogisticRegression(solver='lbfgs')\n",
    "        model.fit(X_train_fs, y_train_enc)\n",
    "        # evaluate the model\n",
    "        yhat = model.predict(X_test_fs)\n",
    "        # evaluate predictions\n",
    "        accuracy_mi = accuracy_score(y_test_enc, yhat)\n",
    "    \n",
    "    return accuracy_full*100, accuracy_chi2*100, accuracy_mi*100\n",
    "\n",
    "#MAIN TESTING LOOP\n",
    "number_of_step=100\n",
    "if dimension > 4: #NO REDUCTION SO FAR\n",
    "    mean_accuracy_full,mean_accuracy_chi2,mean_accuracy_mi=0,0,0\n",
    "    for i in range(number_of_step):\n",
    "        accuracy_full, accuracy_chi2, accuracy_mi=test_uci(X, y, all=True)\n",
    "        mean_accuracy_full+=accuracy_full\n",
    "        mean_accuracy_chi2+=accuracy_chi2\n",
    "        mean_accuracy_mi+=accuracy_mi\n",
    "    \n",
    "    mean_accuracy_full=mean_accuracy_full/number_of_step\n",
    "    mean_accuracy_chi2=mean_accuracy_chi2/number_of_step\n",
    "    mean_accuracy_mi=mean_accuracy_mi/number_of_step\n",
    "    print(mean_accuracy_full,mean_accuracy_chi2,mean_accuracy_mi)\n",
    "else:\n",
    "    #TESTING ON REDUCED DATASED ACCORDING TO AIR RELEVANCE\n",
    "    mean_accuracy_full,mean_accuracy_chi2,mean_accuracy_mi=0,0,0\n",
    "    for i in range(number_of_step):\n",
    "        accuracy_full, _, _=test_uci(X, y, all=False)\n",
    "        mean_accuracy_full+=accuracy_full\n",
    "    \n",
    "    mean_accuracy_full=mean_accuracy_full/number_of_step\n",
    "    print(mean_accuracy_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
